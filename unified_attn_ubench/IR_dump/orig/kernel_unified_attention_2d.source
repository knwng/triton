#loc = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":50:0)
#loc44 = loc(unknown)
#loc170 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":27:0)
#loc174 = loc("left")
#loc175 = loc("right")
#loc193 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":14:0)
#loc199 = loc("/app/OAI-triton/python/triton/language/standard.py":175:0)
#loc203 = loc("/app/OAI-triton/python/triton/language/standard.py":167:0)
#loc207 = loc("/app/OAI-triton/python/triton/language/standard.py":285:0)
#loc211 = loc("/app/OAI-triton/python/triton/language/standard.py":260:0)
#loc215 = loc("output_ptr"(#loc))
#loc216 = loc("query_ptr"(#loc))
#loc217 = loc("key_cache_ptr"(#loc))
#loc218 = loc("value_cache_ptr"(#loc))
#loc219 = loc("sink_ptr"(#loc))
#loc220 = loc("block_tables_ptr"(#loc))
#loc221 = loc("seq_lens_ptr"(#loc))
#loc222 = loc("scale"(#loc))
#loc223 = loc("k_scale"(#loc))
#loc224 = loc("v_scale"(#loc))
#loc225 = loc("out_scale"(#loc))
#loc226 = loc("softcap"(#loc))
#loc227 = loc("block_table_stride"(#loc))
#loc228 = loc("query_stride_0"(#loc))
#loc229 = loc("query_stride_1"(#loc))
#loc230 = loc("output_stride_0"(#loc))
#loc231 = loc("output_stride_1"(#loc))
#loc232 = loc("qq_bias_stride_0"(#loc))
#loc233 = loc("stride_k_cache_0"(#loc))
#loc234 = loc("stride_k_cache_1"(#loc))
#loc235 = loc("stride_k_cache_2"(#loc))
#loc236 = loc("stride_v_cache_0"(#loc))
#loc237 = loc("stride_v_cache_1"(#loc))
#loc238 = loc("stride_v_cache_2"(#loc))
#loc239 = loc("query_start_len_ptr"(#loc))
#loc240 = loc("num_seqs"(#loc))
#loc371 = loc("query_start_len_ptr"(#loc170))
#loc372 = loc("target_idx"(#loc170))
#loc373 = loc("num_seqs"(#loc170))
#loc376 = loc("left"(#loc174))
#loc377 = loc("right"(#loc175))
#loc385 = loc("x"(#loc193))
#loc386 = loc("input"(#loc199))
#loc387 = loc("a"(#loc203))
#loc388 = loc("b"(#loc203))
#loc389 = loc("input"(#loc207))
#loc390 = loc("a"(#loc211))
#loc391 = loc("b"(#loc211))
#loc393 = loc("right"(#loc373))
module {
  tt.func public @kernel_unified_attention_2d(%output_ptr: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("output_ptr"(#loc)), %query_ptr: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("query_ptr"(#loc)), %key_cache_ptr: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("key_cache_ptr"(#loc)), %value_cache_ptr: !tt.ptr<bf16> {tt.divisibility = 16 : i32} loc("value_cache_ptr"(#loc)), %sink_ptr: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("sink_ptr"(#loc)), %block_tables_ptr: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("block_tables_ptr"(#loc)), %seq_lens_ptr: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("seq_lens_ptr"(#loc)), %scale: f32 loc("scale"(#loc)), %k_scale: !tt.ptr<f32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("k_scale"(#loc)), %v_scale: !tt.ptr<f32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("v_scale"(#loc)), %out_scale: f32 loc("out_scale"(#loc)), %softcap: i32 {tt.divisibility = 16 : i32} loc("softcap"(#loc)), %block_table_stride: i64 {tt.divisibility = 16 : i32} loc("block_table_stride"(#loc)), %query_stride_0: i64 {tt.divisibility = 16 : i32} loc("query_stride_0"(#loc)), %query_stride_1: i64 {tt.divisibility = 16 : i32} loc("query_stride_1"(#loc)), %output_stride_0: i64 {tt.divisibility = 16 : i32} loc("output_stride_0"(#loc)), %output_stride_1: i64 {tt.divisibility = 16 : i32} loc("output_stride_1"(#loc)), %qq_bias_stride_0: i64 {tt.divisibility = 16 : i32} loc("qq_bias_stride_0"(#loc)), %stride_k_cache_0: i64 {tt.divisibility = 16 : i32} loc("stride_k_cache_0"(#loc)), %stride_k_cache_1: i64 {tt.divisibility = 16 : i32} loc("stride_k_cache_1"(#loc)), %stride_k_cache_2: i64 {tt.divisibility = 16 : i32} loc("stride_k_cache_2"(#loc)), %stride_v_cache_0: i64 {tt.divisibility = 16 : i32} loc("stride_v_cache_0"(#loc)), %stride_v_cache_1: i64 {tt.divisibility = 16 : i32} loc("stride_v_cache_1"(#loc)), %stride_v_cache_2: i64 {tt.divisibility = 16 : i32} loc("stride_v_cache_2"(#loc)), %query_start_len_ptr: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("query_start_len_ptr"(#loc)), %num_seqs: i32 loc("num_seqs"(#loc))) attributes {noinline = false} {
    %kv_head_idx = tt.get_program_id x : i32 loc(#loc241)
    %q_block_global_idx = tt.get_program_id y : i32 loc(#loc242)
    %c0_i32 = arith.constant 0 : i32 loc(#loc3)
    %0 = arith.cmpi sge, %kv_head_idx, %c0_i32 : i32 loc(#loc3)
    llvm.intr.assume %0 : i1 loc(#loc4)
    %c0_i32_0 = arith.constant 0 : i32 loc(#loc5)
    %1 = arith.cmpi sge, %q_block_global_idx, %c0_i32_0 : i32 loc(#loc5)
    llvm.intr.assume %1 : i1 loc(#loc6)
    %c0_i32_1 = arith.constant 0 : i32 loc(#loc7)
    %2 = arith.extsi %c0_i32_1 : i32 to i64 loc(#loc7)
    %3 = arith.cmpi sgt, %block_table_stride, %2 : i64 loc(#loc7)
    llvm.intr.assume %3 : i1 loc(#loc8)
    %c0_i32_2 = arith.constant 0 : i32 loc(#loc9)
    %4 = arith.extsi %c0_i32_2 : i32 to i64 loc(#loc9)
    %5 = arith.cmpi sgt, %query_stride_0, %4 : i64 loc(#loc9)
    llvm.intr.assume %5 : i1 loc(#loc10)
    %c0_i32_3 = arith.constant 0 : i32 loc(#loc11)
    %6 = arith.extsi %c0_i32_3 : i32 to i64 loc(#loc11)
    %7 = arith.cmpi sgt, %query_stride_1, %6 : i64 loc(#loc11)
    llvm.intr.assume %7 : i1 loc(#loc12)
    %c0_i32_4 = arith.constant 0 : i32 loc(#loc13)
    %8 = arith.extsi %c0_i32_4 : i32 to i64 loc(#loc13)
    %9 = arith.cmpi sgt, %output_stride_0, %8 : i64 loc(#loc13)
    llvm.intr.assume %9 : i1 loc(#loc14)
    %c0_i32_5 = arith.constant 0 : i32 loc(#loc15)
    %10 = arith.extsi %c0_i32_5 : i32 to i64 loc(#loc15)
    %11 = arith.cmpi sgt, %output_stride_1, %10 : i64 loc(#loc15)
    llvm.intr.assume %11 : i1 loc(#loc16)
    %c0_i32_6 = arith.constant 0 : i32 loc(#loc17)
    %12 = arith.extsi %c0_i32_6 : i32 to i64 loc(#loc17)
    %13 = arith.cmpi sgt, %stride_k_cache_0, %12 : i64 loc(#loc17)
    llvm.intr.assume %13 : i1 loc(#loc18)
    %c0_i32_7 = arith.constant 0 : i32 loc(#loc19)
    %14 = arith.extsi %c0_i32_7 : i32 to i64 loc(#loc19)
    %15 = arith.cmpi sgt, %stride_k_cache_1, %14 : i64 loc(#loc19)
    llvm.intr.assume %15 : i1 loc(#loc20)
    %c0_i32_8 = arith.constant 0 : i32 loc(#loc21)
    %16 = arith.extsi %c0_i32_8 : i32 to i64 loc(#loc21)
    %17 = arith.cmpi sgt, %stride_k_cache_2, %16 : i64 loc(#loc21)
    llvm.intr.assume %17 : i1 loc(#loc22)
    %c0_i32_9 = arith.constant 0 : i32 loc(#loc23)
    %18 = arith.extsi %c0_i32_9 : i32 to i64 loc(#loc23)
    %19 = arith.cmpi sgt, %stride_v_cache_0, %18 : i64 loc(#loc23)
    llvm.intr.assume %19 : i1 loc(#loc24)
    %c0_i32_10 = arith.constant 0 : i32 loc(#loc25)
    %20 = arith.extsi %c0_i32_10 : i32 to i64 loc(#loc25)
    %21 = arith.cmpi sgt, %stride_v_cache_1, %20 : i64 loc(#loc25)
    llvm.intr.assume %21 : i1 loc(#loc26)
    %c0_i32_11 = arith.constant 0 : i32 loc(#loc27)
    %22 = arith.extsi %c0_i32_11 : i32 to i64 loc(#loc27)
    %23 = arith.cmpi sgt, %stride_v_cache_2, %22 : i64 loc(#loc27)
    llvm.intr.assume %23 : i1 loc(#loc28)
    %seq_idx = tt.call @"unified_attention_aiter.find_seq_idx__Pi32_i32_i32__(3,)cconstexpr_16__(4,)cconstexpr_True_"(%query_start_len_ptr, %q_block_global_idx, %num_seqs) : (!tt.ptr<i32>, i32, i32) -> i32 loc(#loc243)
    %q_block_start_idx = tt.addptr %query_start_len_ptr, %seq_idx : !tt.ptr<i32>, i32 loc(#loc244)
    %q_block_start_idx_12 = tt.load %q_block_start_idx : !tt.ptr<i32> loc(#loc245)
    %q_block_start_idx_13 = arith.constant 16 : i32 loc(#loc246)
    %q_block_start_idx_14 = arith.constant 16 : i32 loc(#loc246)
    %q_block_start_idx_15 = arith.divsi %q_block_start_idx_12, %q_block_start_idx_14 : i32 loc(#loc246)
    %q_block_start_idx_16 = arith.extsi %q_block_start_idx_15 : i32 to i64 loc(#loc247)
    %q_block_start_idx_17 = arith.extsi %seq_idx : i32 to i64 loc(#loc247)
    %q_block_start_idx_18 = arith.addi %q_block_start_idx_16, %q_block_start_idx_17 : i64 loc(#loc247)
    %q_block_start_idx_19 = arith.constant 2147483647 : i64 loc(#loc247)
    %q_block_start_idx_20 = arith.constant -2147483648 : i64 loc(#loc247)
    %q_block_start_idx_21 = arith.cmpi sle, %q_block_start_idx_18, %q_block_start_idx_19 : i64 loc(#loc247)
    %q_block_start_idx_22 = arith.cmpi sge, %q_block_start_idx_18, %q_block_start_idx_20 : i64 loc(#loc247)
    %q_block_start_idx_23 = arith.andi %q_block_start_idx_21, %q_block_start_idx_22 : i1 loc(#loc247)
    %q_block_start_idx_24 = arith.addi %q_block_start_idx_15, %seq_idx : i32 loc(#loc247)
    %q_block_local_idx = arith.extsi %q_block_global_idx : i32 to i64 loc(#loc248)
    %q_block_local_idx_25 = arith.extsi %q_block_start_idx_24 : i32 to i64 loc(#loc248)
    %q_block_local_idx_26 = arith.subi %q_block_local_idx, %q_block_local_idx_25 : i64 loc(#loc248)
    %q_block_local_idx_27 = arith.constant 2147483647 : i64 loc(#loc248)
    %q_block_local_idx_28 = arith.constant -2147483648 : i64 loc(#loc248)
    %q_block_local_idx_29 = arith.cmpi sle, %q_block_local_idx_26, %q_block_local_idx_27 : i64 loc(#loc248)
    %q_block_local_idx_30 = arith.cmpi sge, %q_block_local_idx_26, %q_block_local_idx_28 : i64 loc(#loc248)
    %q_block_local_idx_31 = arith.andi %q_block_local_idx_29, %q_block_local_idx_30 : i1 loc(#loc248)
    %q_block_local_idx_32 = arith.subi %q_block_global_idx, %q_block_start_idx_24 : i32 loc(#loc248)
    %cur_batch_in_all_start_index = tt.addptr %query_start_len_ptr, %seq_idx : !tt.ptr<i32>, i32 loc(#loc249)
    %cur_batch_in_all_start_index_33 = tt.load %cur_batch_in_all_start_index : !tt.ptr<i32> loc(#loc250)
    %cur_batch_in_all_stop_index = tt.addptr %query_start_len_ptr, %seq_idx : !tt.ptr<i32>, i32 loc(#loc251)
    %cur_batch_in_all_stop_index_34 = arith.constant 1 : i32 loc(#loc252)
    %cur_batch_in_all_stop_index_35 = tt.addptr %cur_batch_in_all_stop_index, %cur_batch_in_all_stop_index_34 : !tt.ptr<i32>, i32 loc(#loc252)
    %cur_batch_in_all_stop_index_36 = tt.load %cur_batch_in_all_stop_index_35 : !tt.ptr<i32> loc(#loc253)
    %cur_batch_query_len = arith.extsi %cur_batch_in_all_stop_index_36 : i32 to i64 loc(#loc254)
    %cur_batch_query_len_37 = arith.extsi %cur_batch_in_all_start_index_33 : i32 to i64 loc(#loc254)
    %cur_batch_query_len_38 = arith.subi %cur_batch_query_len, %cur_batch_query_len_37 : i64 loc(#loc254)
    %cur_batch_query_len_39 = arith.constant 2147483647 : i64 loc(#loc254)
    %cur_batch_query_len_40 = arith.constant -2147483648 : i64 loc(#loc254)
    %cur_batch_query_len_41 = arith.cmpi sle, %cur_batch_query_len_38, %cur_batch_query_len_39 : i64 loc(#loc254)
    %cur_batch_query_len_42 = arith.cmpi sge, %cur_batch_query_len_38, %cur_batch_query_len_40 : i64 loc(#loc254)
    %cur_batch_query_len_43 = arith.andi %cur_batch_query_len_41, %cur_batch_query_len_42 : i1 loc(#loc254)
    %cur_batch_query_len_44 = arith.subi %cur_batch_in_all_stop_index_36, %cur_batch_in_all_start_index_33 : i32 loc(#loc254)
    %c16_i32 = arith.constant 16 : i32 loc(#loc41)
    %c16_i32_45 = arith.constant 16 : i32 loc(#loc41)
    %24 = arith.extsi %q_block_local_idx_32 : i32 to i64 loc(#loc41)
    %25 = arith.extsi %c16_i32_45 : i32 to i64 loc(#loc41)
    %26 = arith.muli %24, %25 : i64 loc(#loc41)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc41)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc41)
    %27 = arith.cmpi sle, %26, %c2147483647_i64 : i64 loc(#loc41)
    %28 = arith.cmpi sge, %26, %c-2147483648_i64 : i64 loc(#loc41)
    %29 = arith.andi %27, %28 : i1 loc(#loc41)
    %30 = arith.muli %q_block_local_idx_32, %c16_i32_45 : i32 loc(#loc41)
    %31 = arith.cmpi sge, %30, %cur_batch_query_len_44 : i32 loc(#loc42)
    cf.cond_br %31, ^bb1, ^bb2 loc(#loc42)
  ^bb1:  // pred: ^bb0
    tt.return loc(#loc43)
  ^bb2:  // pred: ^bb0
    cf.br ^bb4 loc(#loc44)
  ^bb3:  // no predecessors
    cf.br ^bb4 loc(#loc44)
  ^bb4:  // 2 preds: ^bb2, ^bb3
    %offs_m = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32> loc(#loc255)
    %offs_d = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32> loc(#loc256)
    %query_pos = arith.constant 16 : i32 loc(#loc257)
    %query_pos_46 = arith.constant 16 : i32 loc(#loc257)
    %query_pos_47 = arith.extsi %q_block_local_idx_32 : i32 to i64 loc(#loc257)
    %query_pos_48 = arith.extsi %query_pos_46 : i32 to i64 loc(#loc257)
    %query_pos_49 = arith.muli %query_pos_47, %query_pos_48 : i64 loc(#loc257)
    %query_pos_50 = arith.constant 2147483647 : i64 loc(#loc257)
    %query_pos_51 = arith.constant -2147483648 : i64 loc(#loc257)
    %query_pos_52 = arith.cmpi sle, %query_pos_49, %query_pos_50 : i64 loc(#loc257)
    %query_pos_53 = arith.cmpi sge, %query_pos_49, %query_pos_51 : i64 loc(#loc257)
    %query_pos_54 = arith.andi %query_pos_52, %query_pos_53 : i1 loc(#loc257)
    %query_pos_55 = arith.muli %q_block_local_idx_32, %query_pos_46 : i32 loc(#loc257)
    %query_pos_56 = arith.constant 8 : i32 loc(#loc258)
    %query_pos_57 = arith.constant 8 : i32 loc(#loc258)
    %query_pos_58 = arith.constant dense<8> : tensor<128xi32> loc(#loc258)
    %query_pos_59 = arith.divsi %offs_m, %query_pos_58 : tensor<128xi32> loc(#loc258)
    %query_pos_60 = tt.splat %query_pos_55 : i32 -> tensor<128xi32> loc(#loc259)
    %query_pos_61 = arith.extsi %query_pos_60 : tensor<128xi32> to tensor<128xi64> loc(#loc259)
    %query_pos_62 = arith.extsi %query_pos_59 : tensor<128xi32> to tensor<128xi64> loc(#loc259)
    %query_pos_63 = arith.addi %query_pos_61, %query_pos_62 : tensor<128xi64> loc(#loc259)
    %query_pos_64 = arith.constant 2147483647 : i64 loc(#loc259)
    %query_pos_65 = arith.constant -2147483648 : i64 loc(#loc259)
    %query_pos_66 = arith.constant dense<2147483647> : tensor<128xi64> loc(#loc259)
    %query_pos_67 = arith.cmpi sle, %query_pos_63, %query_pos_66 : tensor<128xi64> loc(#loc259)
    %query_pos_68 = arith.constant dense<-2147483648> : tensor<128xi64> loc(#loc259)
    %query_pos_69 = arith.cmpi sge, %query_pos_63, %query_pos_68 : tensor<128xi64> loc(#loc259)
    %query_pos_70 = arith.andi %query_pos_67, %query_pos_69 : tensor<128xi1> loc(#loc259)
    %query_pos_71 = arith.addi %query_pos_60, %query_pos_59 : tensor<128xi32> loc(#loc259)
    %query_offset_0 = tt.splat %cur_batch_in_all_start_index_33 : i32 -> tensor<128xi32> loc(#loc260)
    %query_offset_0_72 = arith.extsi %query_offset_0 : tensor<128xi32> to tensor<128xi64> loc(#loc260)
    %query_offset_0_73 = arith.extsi %query_pos_71 : tensor<128xi32> to tensor<128xi64> loc(#loc260)
    %query_offset_0_74 = arith.addi %query_offset_0_72, %query_offset_0_73 : tensor<128xi64> loc(#loc260)
    %query_offset_0_75 = arith.constant 2147483647 : i64 loc(#loc260)
    %query_offset_0_76 = arith.constant -2147483648 : i64 loc(#loc260)
    %query_offset_0_77 = arith.constant dense<2147483647> : tensor<128xi64> loc(#loc260)
    %query_offset_0_78 = arith.cmpi sle, %query_offset_0_74, %query_offset_0_77 : tensor<128xi64> loc(#loc260)
    %query_offset_0_79 = arith.constant dense<-2147483648> : tensor<128xi64> loc(#loc260)
    %query_offset_0_80 = arith.cmpi sge, %query_offset_0_74, %query_offset_0_79 : tensor<128xi64> loc(#loc260)
    %query_offset_0_81 = arith.andi %query_offset_0_78, %query_offset_0_80 : tensor<128xi1> loc(#loc260)
    %query_offset_0_82 = arith.addi %query_offset_0, %query_pos_71 : tensor<128xi32> loc(#loc260)
    %query_offset_1 = arith.constant 8 : i32 loc(#loc261)
    %query_offset_1_83 = arith.constant 8 : i32 loc(#loc261)
    %query_offset_1_84 = arith.extsi %kv_head_idx : i32 to i64 loc(#loc261)
    %query_offset_1_85 = arith.extsi %query_offset_1_83 : i32 to i64 loc(#loc261)
    %query_offset_1_86 = arith.muli %query_offset_1_84, %query_offset_1_85 : i64 loc(#loc261)
    %query_offset_1_87 = arith.constant 2147483647 : i64 loc(#loc261)
    %query_offset_1_88 = arith.constant -2147483648 : i64 loc(#loc261)
    %query_offset_1_89 = arith.cmpi sle, %query_offset_1_86, %query_offset_1_87 : i64 loc(#loc261)
    %query_offset_1_90 = arith.cmpi sge, %query_offset_1_86, %query_offset_1_88 : i64 loc(#loc261)
    %query_offset_1_91 = arith.andi %query_offset_1_89, %query_offset_1_90 : i1 loc(#loc261)
    %query_offset_1_92 = arith.muli %kv_head_idx, %query_offset_1_83 : i32 loc(#loc261)
    %query_offset_1_93 = arith.constant 8 : i32 loc(#loc262)
    %query_offset_1_94 = arith.constant 8 : i32 loc(#loc262)
    %query_offset_1_95 = arith.constant dense<8> : tensor<128xi32> loc(#loc262)
    %query_offset_1_96 = arith.remsi %offs_m, %query_offset_1_95 : tensor<128xi32> loc(#loc262)
    %query_offset_1_97 = tt.splat %query_offset_1_92 : i32 -> tensor<128xi32> loc(#loc263)
    %query_offset_1_98 = arith.extsi %query_offset_1_97 : tensor<128xi32> to tensor<128xi64> loc(#loc263)
    %query_offset_1_99 = arith.extsi %query_offset_1_96 : tensor<128xi32> to tensor<128xi64> loc(#loc263)
    %query_offset_1_100 = arith.addi %query_offset_1_98, %query_offset_1_99 : tensor<128xi64> loc(#loc263)
    %query_offset_1_101 = arith.constant 2147483647 : i64 loc(#loc263)
    %query_offset_1_102 = arith.constant -2147483648 : i64 loc(#loc263)
    %query_offset_1_103 = arith.constant dense<2147483647> : tensor<128xi64> loc(#loc263)
    %query_offset_1_104 = arith.cmpi sle, %query_offset_1_100, %query_offset_1_103 : tensor<128xi64> loc(#loc263)
    %query_offset_1_105 = arith.constant dense<-2147483648> : tensor<128xi64> loc(#loc263)
    %query_offset_1_106 = arith.cmpi sge, %query_offset_1_100, %query_offset_1_105 : tensor<128xi64> loc(#loc263)
    %query_offset_1_107 = arith.andi %query_offset_1_104, %query_offset_1_106 : tensor<128xi1> loc(#loc263)
    %query_offset_1_108 = arith.addi %query_offset_1_97, %query_offset_1_96 : tensor<128xi32> loc(#loc263)
    %query_offset = tt.expand_dims %query_offset_0_82 {axis = 1 : i32} : tensor<128xi32> -> tensor<128x1xi32> loc(#loc264)
    %query_offset_109 = arith.extsi %query_offset : tensor<128x1xi32> to tensor<128x1xi64> loc(#loc265)
    %query_offset_110 = tt.splat %query_stride_0 : i64 -> tensor<128x1xi64> loc(#loc265)
    %query_offset_111 = arith.muli %query_offset_109, %query_offset_110 : tensor<128x1xi64> loc(#loc265)
    %query_offset_112 = tt.expand_dims %query_offset_1_108 {axis = 1 : i32} : tensor<128xi32> -> tensor<128x1xi32> loc(#loc266)
    %query_offset_113 = arith.extsi %query_offset_112 : tensor<128x1xi32> to tensor<128x1xi64> loc(#loc267)
    %query_offset_114 = tt.splat %query_stride_1 : i64 -> tensor<128x1xi64> loc(#loc267)
    %query_offset_115 = arith.muli %query_offset_113, %query_offset_114 : tensor<128x1xi64> loc(#loc267)
    %query_offset_116 = arith.addi %query_offset_111, %query_offset_115 : tensor<128x1xi64> loc(#loc268)
    %query_offset_117 = tt.expand_dims %offs_d {axis = 0 : i32} : tensor<64xi32> -> tensor<1x64xi32> loc(#loc269)
    %query_offset_118 = arith.extsi %query_offset_117 : tensor<1x64xi32> to tensor<1x64xi64> loc(#loc270)
    %query_offset_119 = tt.broadcast %query_offset_116 : tensor<128x1xi64> -> tensor<128x64xi64> loc(#loc270)
    %query_offset_120 = tt.broadcast %query_offset_118 : tensor<1x64xi64> -> tensor<128x64xi64> loc(#loc270)
    %query_offset_121 = arith.addi %query_offset_119, %query_offset_120 : tensor<128x64xi64> loc(#loc270)
    %dim_mask = arith.constant 64 : i32 loc(#loc271)
    %dim_mask_122 = arith.constant dense<64> : tensor<64xi32> loc(#loc271)
    %dim_mask_123 = arith.cmpi slt, %offs_d, %dim_mask_122 : tensor<64xi32> loc(#loc271)
    %dim_mask_124 = arith.constant 1 : i32 loc(#loc272)
    %dim_mask_125 = arith.constant 0 : i32 loc(#loc272)
    %dim_mask_126 = arith.constant 1 : i32 loc(#loc272)
    %dim_mask_127 = arith.constant 0 : i32 loc(#loc272)
    %dim_mask_128 = arith.constant dense<1> : tensor<64xi32> loc(#loc272)
    %dim_mask_129 = arith.constant dense<0> : tensor<64xi32> loc(#loc272)
    %dim_mask_130 = arith.select %dim_mask_123, %dim_mask_128, %dim_mask_129 : tensor<64xi1>, tensor<64xi32> loc(#loc272)
    %dim_mask_131 = arith.constant 0 : i32 loc(#loc273)
    %dim_mask_132 = arith.constant dense<0> : tensor<64xi32> loc(#loc273)
    %dim_mask_133 = arith.cmpi ne, %dim_mask_130, %dim_mask_132 : tensor<64xi32> loc(#loc273)
    %query_mask_0 = tt.splat %cur_batch_query_len_44 : i32 -> tensor<128xi32> loc(#loc274)
    %query_mask_0_134 = arith.cmpi slt, %query_pos_71, %query_mask_0 : tensor<128xi32> loc(#loc274)
    %query_mask_1 = arith.constant 64 : i32 loc(#loc275)
    %query_mask_1_135 = arith.constant dense<64> : tensor<128xi32> loc(#loc275)
    %query_mask_1_136 = arith.cmpi slt, %query_offset_1_108, %query_mask_1_135 : tensor<128xi32> loc(#loc275)
    %Q = tt.expand_dims %dim_mask_133 {axis = 0 : i32} : tensor<64xi1> -> tensor<1x64xi1> loc(#loc276)
    %Q_137 = tt.expand_dims %query_mask_0_134 {axis = 1 : i32} : tensor<128xi1> -> tensor<128x1xi1> loc(#loc277)
    %Q_138 = tt.broadcast %Q : tensor<1x64xi1> -> tensor<128x64xi1> loc(#loc278)
    %Q_139 = tt.broadcast %Q_137 : tensor<128x1xi1> -> tensor<128x64xi1> loc(#loc278)
    %Q_140 = arith.andi %Q_138, %Q_139 : tensor<128x64xi1> loc(#loc278)
    %Q_141 = tt.expand_dims %query_mask_1_136 {axis = 1 : i32} : tensor<128xi1> -> tensor<128x1xi1> loc(#loc279)
    %Q_142 = tt.broadcast %Q_141 : tensor<128x1xi1> -> tensor<128x64xi1> loc(#loc280)
    %Q_143 = arith.andi %Q_140, %Q_142 : tensor<128x64xi1> loc(#loc280)
    %Q_144 = tt.splat %query_ptr : !tt.ptr<bf16> -> tensor<128x64x!tt.ptr<bf16>> loc(#loc281)
    %Q_145 = tt.addptr %Q_144, %query_offset_121 : tensor<128x64x!tt.ptr<bf16>>, tensor<128x64xi64> loc(#loc281)
    %Q_146 = arith.constant 0.000000e+00 : f32 loc(#loc282)
    %Q_147 = arith.constant dense<0.000000e+00> : tensor<128x64xf32> loc(#loc282)
    %Q_148 = arith.truncf %Q_147 : tensor<128x64xf32> to tensor<128x64xbf16> loc(#loc282)
    %Q_149 = tt.load %Q_145, %Q_143, %Q_148 cacheModifier = cg : tensor<128x64x!tt.ptr<bf16>> loc(#loc282)
    %block_table_offset = arith.extsi %seq_idx : i32 to i64 loc(#loc283)
    %block_table_offset_150 = arith.muli %block_table_offset, %block_table_stride : i64 loc(#loc283)
    %M = tt.splat %sink_ptr : !tt.ptr<bf16> -> tensor<128x!tt.ptr<bf16>> loc(#loc284)
    %M_151 = tt.addptr %M, %query_offset_1_108 : tensor<128x!tt.ptr<bf16>>, tensor<128xi32> loc(#loc284)
    %M_152 = arith.constant 0xFF800000 : f32 loc(#loc285)
    %M_153 = arith.constant dense<0xFF800000> : tensor<128xf32> loc(#loc285)
    %M_154 = arith.truncf %M_153 : tensor<128xf32> to tensor<128xbf16> loc(#loc285)
    %M_155 = tt.load %M_151, %query_mask_1_136, %M_154 : tensor<128x!tt.ptr<bf16>> loc(#loc285)
    %M_156 = arith.extf %M_155 : tensor<128xbf16> to tensor<128xf32> loc(#loc286)
    %L = arith.constant 1.000000e+00 : f32 loc(#loc287)
    %L_157 = arith.constant dense<1.000000e+00> : tensor<128xf32> loc(#loc287)
    %acc = tt.call @"triton.language.standard.zeros____(0, 0)cconstexpr_128__(0, 1)cconstexpr_64__(1,)cconstexpr_fp32_"() : () -> tensor<128x64xf32> loc(#loc288)
    %seq_len = tt.addptr %seq_lens_ptr, %seq_idx : !tt.ptr<i32>, i32 loc(#loc289)
    %seq_len_158 = tt.load %seq_len : !tt.ptr<i32> loc(#loc290)
    %context_len = arith.extsi %seq_len_158 : i32 to i64 loc(#loc291)
    %context_len_159 = arith.extsi %cur_batch_query_len_44 : i32 to i64 loc(#loc291)
    %context_len_160 = arith.subi %context_len, %context_len_159 : i64 loc(#loc291)
    %context_len_161 = arith.constant 2147483647 : i64 loc(#loc291)
    %context_len_162 = arith.constant -2147483648 : i64 loc(#loc291)
    %context_len_163 = arith.cmpi sle, %context_len_160, %context_len_161 : i64 loc(#loc291)
    %context_len_164 = arith.cmpi sge, %context_len_160, %context_len_162 : i64 loc(#loc291)
    %context_len_165 = arith.andi %context_len_163, %context_len_164 : i1 loc(#loc291)
    %context_len_166 = arith.subi %seq_len_158, %cur_batch_query_len_44 : i32 loc(#loc291)
    %max_seq_prefix_len = arith.constant 16 : i32 loc(#loc292)
    %max_seq_prefix_len_167 = arith.constant 16 : i32 loc(#loc292)
    %max_seq_prefix_len_168 = arith.extsi %q_block_local_idx_32 : i32 to i64 loc(#loc292)
    %max_seq_prefix_len_169 = arith.extsi %max_seq_prefix_len_167 : i32 to i64 loc(#loc292)
    %max_seq_prefix_len_170 = arith.muli %max_seq_prefix_len_168, %max_seq_prefix_len_169 : i64 loc(#loc292)
    %max_seq_prefix_len_171 = arith.constant 2147483647 : i64 loc(#loc292)
    %max_seq_prefix_len_172 = arith.constant -2147483648 : i64 loc(#loc292)
    %max_seq_prefix_len_173 = arith.cmpi sle, %max_seq_prefix_len_170, %max_seq_prefix_len_171 : i64 loc(#loc292)
    %max_seq_prefix_len_174 = arith.cmpi sge, %max_seq_prefix_len_170, %max_seq_prefix_len_172 : i64 loc(#loc292)
    %max_seq_prefix_len_175 = arith.andi %max_seq_prefix_len_173, %max_seq_prefix_len_174 : i1 loc(#loc292)
    %max_seq_prefix_len_176 = arith.muli %q_block_local_idx_32, %max_seq_prefix_len_167 : i32 loc(#loc292)
    %max_seq_prefix_len_177 = arith.extsi %context_len_166 : i32 to i64 loc(#loc293)
    %max_seq_prefix_len_178 = arith.extsi %max_seq_prefix_len_176 : i32 to i64 loc(#loc293)
    %max_seq_prefix_len_179 = arith.addi %max_seq_prefix_len_177, %max_seq_prefix_len_178 : i64 loc(#loc293)
    %max_seq_prefix_len_180 = arith.constant 2147483647 : i64 loc(#loc293)
    %max_seq_prefix_len_181 = arith.constant -2147483648 : i64 loc(#loc293)
    %max_seq_prefix_len_182 = arith.cmpi sle, %max_seq_prefix_len_179, %max_seq_prefix_len_180 : i64 loc(#loc293)
    %max_seq_prefix_len_183 = arith.cmpi sge, %max_seq_prefix_len_179, %max_seq_prefix_len_181 : i64 loc(#loc293)
    %max_seq_prefix_len_184 = arith.andi %max_seq_prefix_len_182, %max_seq_prefix_len_183 : i1 loc(#loc293)
    %max_seq_prefix_len_185 = arith.addi %context_len_166, %max_seq_prefix_len_176 : i32 loc(#loc293)
    %max_seq_prefix_len_186 = arith.constant 15 : i32 loc(#loc294)
    %max_seq_prefix_len_187 = arith.constant 15 : i32 loc(#loc294)
    %max_seq_prefix_len_188 = arith.extsi %max_seq_prefix_len_185 : i32 to i64 loc(#loc294)
    %max_seq_prefix_len_189 = arith.extsi %max_seq_prefix_len_187 : i32 to i64 loc(#loc294)
    %max_seq_prefix_len_190 = arith.addi %max_seq_prefix_len_188, %max_seq_prefix_len_189 : i64 loc(#loc294)
    %max_seq_prefix_len_191 = arith.constant 2147483647 : i64 loc(#loc294)
    %max_seq_prefix_len_192 = arith.constant -2147483648 : i64 loc(#loc294)
    %max_seq_prefix_len_193 = arith.cmpi sle, %max_seq_prefix_len_190, %max_seq_prefix_len_191 : i64 loc(#loc294)
    %max_seq_prefix_len_194 = arith.cmpi sge, %max_seq_prefix_len_190, %max_seq_prefix_len_192 : i64 loc(#loc294)
    %max_seq_prefix_len_195 = arith.andi %max_seq_prefix_len_193, %max_seq_prefix_len_194 : i1 loc(#loc294)
    %max_seq_prefix_len_196 = arith.addi %max_seq_prefix_len_185, %max_seq_prefix_len_187 : i32 loc(#loc294)
    %max_seq_prefix_len_197 = arith.constant 1 : i32 loc(#loc295)
    %max_seq_prefix_len_198 = arith.constant 1 : i32 loc(#loc295)
    %max_seq_prefix_len_199 = arith.extsi %max_seq_prefix_len_196 : i32 to i64 loc(#loc295)
    %max_seq_prefix_len_200 = arith.extsi %max_seq_prefix_len_198 : i32 to i64 loc(#loc295)
    %max_seq_prefix_len_201 = arith.addi %max_seq_prefix_len_199, %max_seq_prefix_len_200 : i64 loc(#loc295)
    %max_seq_prefix_len_202 = arith.constant 2147483647 : i64 loc(#loc295)
    %max_seq_prefix_len_203 = arith.constant -2147483648 : i64 loc(#loc295)
    %max_seq_prefix_len_204 = arith.cmpi sle, %max_seq_prefix_len_201, %max_seq_prefix_len_202 : i64 loc(#loc295)
    %max_seq_prefix_len_205 = arith.cmpi sge, %max_seq_prefix_len_201, %max_seq_prefix_len_203 : i64 loc(#loc295)
    %max_seq_prefix_len_206 = arith.andi %max_seq_prefix_len_204, %max_seq_prefix_len_205 : i1 loc(#loc295)
    %max_seq_prefix_len_207 = arith.addi %max_seq_prefix_len_196, %max_seq_prefix_len_198 : i32 loc(#loc295)
    %max_seq_prefix_len_208 = arith.minsi %max_seq_prefix_len_207, %seq_len_158 : i32 loc(#loc296)
    %num_blocks = tt.call @"unified_attention_aiter.cdiv_fn__i32__(1,)cconstexpr_64_"(%max_seq_prefix_len_208) : (i32) -> i32 loc(#loc297)
    %num_blocks_start = arith.constant 0 : i32 loc(#loc298)
    %c1_i32 = arith.constant 1 : i32 loc(#loc89)
    %32 = arith.bitcast %num_blocks_start : i32 to i32 loc(#loc89)
    %33 = arith.bitcast %num_blocks : i32 to i32 loc(#loc89)
    %34 = arith.bitcast %c1_i32 : i32 to i32 loc(#loc89)
    %35 = ub.poison : i32 loc(#loc89)
    %acc_209:3 = scf.for %j = %32 to %33 step %34 iter_args(%M_229 = %M_156, %L_230 = %L_157, %acc_231 = %acc) -> (tensor<128xf32>, tensor<128xf32>, tensor<128x64xf32>)  : i32 {
      %physical_block_idx = tt.addptr %block_tables_ptr, %block_table_offset_150 : !tt.ptr<i32>, i64 loc(#loc300)
      %physical_block_idx_232 = tt.addptr %physical_block_idx, %j : !tt.ptr<i32>, i32 loc(#loc301)
      %physical_block_idx_233 = tt.load %physical_block_idx_232 : !tt.ptr<i32> loc(#loc302)
      %offs_n = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32> loc(#loc303)
      %v_offset = arith.extsi %physical_block_idx_233 : i32 to i64 loc(#loc304)
      %v_offset_234 = arith.muli %v_offset, %stride_v_cache_0 : i64 loc(#loc304)
      %v_offset_235 = arith.extsi %kv_head_idx : i32 to i64 loc(#loc305)
      %v_offset_236 = arith.muli %v_offset_235, %stride_v_cache_2 : i64 loc(#loc305)
      %v_offset_237 = arith.addi %v_offset_234, %v_offset_236 : i64 loc(#loc306)
      %v_offset_238 = tt.expand_dims %offs_d {axis = 0 : i32} : tensor<64xi32> -> tensor<1x64xi32> loc(#loc307)
      %v_offset_239 = arith.constant 1 : i32 loc(#loc308)
      %v_offset_240 = arith.constant 1 : i32 loc(#loc308)
      %v_offset_241 = arith.constant dense<1> : tensor<1x64xi32> loc(#loc308)
      %v_offset_242 = arith.extsi %v_offset_238 : tensor<1x64xi32> to tensor<1x64xi64> loc(#loc308)
      %v_offset_243 = arith.extsi %v_offset_241 : tensor<1x64xi32> to tensor<1x64xi64> loc(#loc308)
      %v_offset_244 = arith.muli %v_offset_242, %v_offset_243 : tensor<1x64xi64> loc(#loc308)
      %v_offset_245 = arith.constant 2147483647 : i64 loc(#loc308)
      %v_offset_246 = arith.constant -2147483648 : i64 loc(#loc308)
      %v_offset_247 = arith.constant dense<2147483647> : tensor<1x64xi64> loc(#loc308)
      %v_offset_248 = arith.cmpi sle, %v_offset_244, %v_offset_247 : tensor<1x64xi64> loc(#loc308)
      %v_offset_249 = arith.constant dense<-2147483648> : tensor<1x64xi64> loc(#loc308)
      %v_offset_250 = arith.cmpi sge, %v_offset_244, %v_offset_249 : tensor<1x64xi64> loc(#loc308)
      %v_offset_251 = arith.andi %v_offset_248, %v_offset_250 : tensor<1x64xi1> loc(#loc308)
      %v_offset_252 = arith.muli %v_offset_238, %v_offset_241 : tensor<1x64xi32> loc(#loc308)
      %v_offset_253 = arith.extsi %v_offset_252 : tensor<1x64xi32> to tensor<1x64xi64> loc(#loc309)
      %v_offset_254 = tt.splat %v_offset_237 : i64 -> tensor<1x64xi64> loc(#loc309)
      %v_offset_255 = arith.addi %v_offset_254, %v_offset_253 : tensor<1x64xi64> loc(#loc309)
      %v_offset_256 = tt.expand_dims %offs_n {axis = 1 : i32} : tensor<64xi32> -> tensor<64x1xi32> loc(#loc310)
      %v_offset_257 = arith.extsi %v_offset_256 : tensor<64x1xi32> to tensor<64x1xi64> loc(#loc311)
      %v_offset_258 = tt.splat %stride_v_cache_1 : i64 -> tensor<64x1xi64> loc(#loc311)
      %v_offset_259 = arith.muli %v_offset_257, %v_offset_258 : tensor<64x1xi64> loc(#loc311)
      %v_offset_260 = tt.broadcast %v_offset_255 : tensor<1x64xi64> -> tensor<64x64xi64> loc(#loc312)
      %v_offset_261 = tt.broadcast %v_offset_259 : tensor<64x1xi64> -> tensor<64x64xi64> loc(#loc312)
      %v_offset_262 = arith.addi %v_offset_260, %v_offset_261 : tensor<64x64xi64> loc(#loc312)
      %k_offset = arith.extsi %physical_block_idx_233 : i32 to i64 loc(#loc313)
      %k_offset_263 = arith.muli %k_offset, %stride_k_cache_0 : i64 loc(#loc313)
      %k_offset_264 = arith.extsi %kv_head_idx : i32 to i64 loc(#loc314)
      %k_offset_265 = arith.muli %k_offset_264, %stride_k_cache_2 : i64 loc(#loc314)
      %k_offset_266 = arith.addi %k_offset_263, %k_offset_265 : i64 loc(#loc315)
      %k_offset_267 = tt.expand_dims %offs_d {axis = 1 : i32} : tensor<64xi32> -> tensor<64x1xi32> loc(#loc316)
      %k_offset_268 = arith.constant 1 : i32 loc(#loc317)
      %k_offset_269 = arith.constant 1 : i32 loc(#loc317)
      %k_offset_270 = arith.constant dense<1> : tensor<64x1xi32> loc(#loc317)
      %k_offset_271 = arith.extsi %k_offset_267 : tensor<64x1xi32> to tensor<64x1xi64> loc(#loc317)
      %k_offset_272 = arith.extsi %k_offset_270 : tensor<64x1xi32> to tensor<64x1xi64> loc(#loc317)
      %k_offset_273 = arith.muli %k_offset_271, %k_offset_272 : tensor<64x1xi64> loc(#loc317)
      %k_offset_274 = arith.constant 2147483647 : i64 loc(#loc317)
      %k_offset_275 = arith.constant -2147483648 : i64 loc(#loc317)
      %k_offset_276 = arith.constant dense<2147483647> : tensor<64x1xi64> loc(#loc317)
      %k_offset_277 = arith.cmpi sle, %k_offset_273, %k_offset_276 : tensor<64x1xi64> loc(#loc317)
      %k_offset_278 = arith.constant dense<-2147483648> : tensor<64x1xi64> loc(#loc317)
      %k_offset_279 = arith.cmpi sge, %k_offset_273, %k_offset_278 : tensor<64x1xi64> loc(#loc317)
      %k_offset_280 = arith.andi %k_offset_277, %k_offset_279 : tensor<64x1xi1> loc(#loc317)
      %k_offset_281 = arith.muli %k_offset_267, %k_offset_270 : tensor<64x1xi32> loc(#loc317)
      %k_offset_282 = arith.extsi %k_offset_281 : tensor<64x1xi32> to tensor<64x1xi64> loc(#loc318)
      %k_offset_283 = tt.splat %k_offset_266 : i64 -> tensor<64x1xi64> loc(#loc318)
      %k_offset_284 = arith.addi %k_offset_283, %k_offset_282 : tensor<64x1xi64> loc(#loc318)
      %k_offset_285 = tt.expand_dims %offs_n {axis = 0 : i32} : tensor<64xi32> -> tensor<1x64xi32> loc(#loc319)
      %k_offset_286 = arith.extsi %k_offset_285 : tensor<1x64xi32> to tensor<1x64xi64> loc(#loc320)
      %k_offset_287 = tt.splat %stride_k_cache_1 : i64 -> tensor<1x64xi64> loc(#loc320)
      %k_offset_288 = arith.muli %k_offset_286, %k_offset_287 : tensor<1x64xi64> loc(#loc320)
      %k_offset_289 = tt.broadcast %k_offset_284 : tensor<64x1xi64> -> tensor<64x64xi64> loc(#loc321)
      %k_offset_290 = tt.broadcast %k_offset_288 : tensor<1x64xi64> -> tensor<64x64xi64> loc(#loc321)
      %k_offset_291 = arith.addi %k_offset_289, %k_offset_290 : tensor<64x64xi64> loc(#loc321)
      %K_load = tt.expand_dims %dim_mask_133 {axis = 1 : i32} : tensor<64xi1> -> tensor<64x1xi1> loc(#loc322)
      %K_load_292 = tt.splat %key_cache_ptr : !tt.ptr<bf16> -> tensor<64x64x!tt.ptr<bf16>> loc(#loc323)
      %K_load_293 = tt.addptr %K_load_292, %k_offset_291 : tensor<64x64x!tt.ptr<bf16>>, tensor<64x64xi64> loc(#loc323)
      %K_load_294 = arith.constant 0.000000e+00 : f32 loc(#loc324)
      %K_load_295 = tt.broadcast %K_load : tensor<64x1xi1> -> tensor<64x64xi1> loc(#loc324)
      %K_load_296 = arith.constant dense<0.000000e+00> : tensor<64x64xf32> loc(#loc324)
      %K_load_297 = arith.truncf %K_load_296 : tensor<64x64xf32> to tensor<64x64xbf16> loc(#loc324)
      %K_load_298 = tt.load %K_load_293, %K_load_295, %K_load_297 : tensor<64x64x!tt.ptr<bf16>> loc(#loc324)
      %V_load = tt.expand_dims %dim_mask_133 {axis = 0 : i32} : tensor<64xi1> -> tensor<1x64xi1> loc(#loc325)
      %V_load_299 = tt.splat %value_cache_ptr : !tt.ptr<bf16> -> tensor<64x64x!tt.ptr<bf16>> loc(#loc326)
      %V_load_300 = tt.addptr %V_load_299, %v_offset_262 : tensor<64x64x!tt.ptr<bf16>>, tensor<64x64xi64> loc(#loc326)
      %V_load_301 = arith.constant 0.000000e+00 : f32 loc(#loc327)
      %V_load_302 = tt.broadcast %V_load : tensor<1x64xi1> -> tensor<64x64xi1> loc(#loc327)
      %V_load_303 = arith.constant dense<0.000000e+00> : tensor<64x64xf32> loc(#loc327)
      %V_load_304 = arith.truncf %V_load_303 : tensor<64x64xf32> to tensor<64x64xbf16> loc(#loc327)
      %V_load_305 = tt.load %V_load_300, %V_load_302, %V_load_304 : tensor<64x64x!tt.ptr<bf16>> loc(#loc327)
      %seq_offset = arith.constant 64 : i32 loc(#loc328)
      %seq_offset_306 = arith.constant 64 : i32 loc(#loc328)
      %seq_offset_307 = arith.extsi %j : i32 to i64 loc(#loc328)
      %seq_offset_308 = arith.extsi %seq_offset_306 : i32 to i64 loc(#loc328)
      %seq_offset_309 = arith.muli %seq_offset_307, %seq_offset_308 : i64 loc(#loc328)
      %seq_offset_310 = arith.constant 2147483647 : i64 loc(#loc328)
      %seq_offset_311 = arith.constant -2147483648 : i64 loc(#loc328)
      %seq_offset_312 = arith.cmpi sle, %seq_offset_309, %seq_offset_310 : i64 loc(#loc328)
      %seq_offset_313 = arith.cmpi sge, %seq_offset_309, %seq_offset_311 : i64 loc(#loc328)
      %seq_offset_314 = arith.andi %seq_offset_312, %seq_offset_313 : i1 loc(#loc328)
      %seq_offset_315 = arith.muli %j, %seq_offset_306 : i32 loc(#loc328)
      %seq_offset_316 = tt.splat %seq_offset_315 : i32 -> tensor<64xi32> loc(#loc329)
      %seq_offset_317 = arith.extsi %seq_offset_316 : tensor<64xi32> to tensor<64xi64> loc(#loc329)
      %seq_offset_318 = arith.extsi %offs_n : tensor<64xi32> to tensor<64xi64> loc(#loc329)
      %seq_offset_319 = arith.addi %seq_offset_317, %seq_offset_318 : tensor<64xi64> loc(#loc329)
      %seq_offset_320 = arith.constant 2147483647 : i64 loc(#loc329)
      %seq_offset_321 = arith.constant -2147483648 : i64 loc(#loc329)
      %seq_offset_322 = arith.constant dense<2147483647> : tensor<64xi64> loc(#loc329)
      %seq_offset_323 = arith.cmpi sle, %seq_offset_319, %seq_offset_322 : tensor<64xi64> loc(#loc329)
      %seq_offset_324 = arith.constant dense<-2147483648> : tensor<64xi64> loc(#loc329)
      %seq_offset_325 = arith.cmpi sge, %seq_offset_319, %seq_offset_324 : tensor<64xi64> loc(#loc329)
      %seq_offset_326 = arith.andi %seq_offset_323, %seq_offset_325 : tensor<64xi1> loc(#loc329)
      %seq_offset_327 = arith.addi %seq_offset_316, %offs_n : tensor<64xi32> loc(#loc329)
      %seq_mask = tt.expand_dims %seq_offset_327 {axis = 0 : i32} : tensor<64xi32> -> tensor<1x64xi32> loc(#loc330)
      %seq_mask_328 = tt.expand_dims %query_pos_71 {axis = 1 : i32} : tensor<128xi32> -> tensor<128x1xi32> loc(#loc331)
      %seq_mask_329 = tt.splat %context_len_166 : i32 -> tensor<128x1xi32> loc(#loc332)
      %seq_mask_330 = arith.extsi %seq_mask_329 : tensor<128x1xi32> to tensor<128x1xi64> loc(#loc332)
      %seq_mask_331 = arith.extsi %seq_mask_328 : tensor<128x1xi32> to tensor<128x1xi64> loc(#loc332)
      %seq_mask_332 = arith.addi %seq_mask_330, %seq_mask_331 : tensor<128x1xi64> loc(#loc332)
      %seq_mask_333 = arith.constant 2147483647 : i64 loc(#loc332)
      %seq_mask_334 = arith.constant -2147483648 : i64 loc(#loc332)
      %seq_mask_335 = arith.constant dense<2147483647> : tensor<128x1xi64> loc(#loc332)
      %seq_mask_336 = arith.cmpi sle, %seq_mask_332, %seq_mask_335 : tensor<128x1xi64> loc(#loc332)
      %seq_mask_337 = arith.constant dense<-2147483648> : tensor<128x1xi64> loc(#loc332)
      %seq_mask_338 = arith.cmpi sge, %seq_mask_332, %seq_mask_337 : tensor<128x1xi64> loc(#loc332)
      %seq_mask_339 = arith.andi %seq_mask_336, %seq_mask_338 : tensor<128x1xi1> loc(#loc332)
      %seq_mask_340 = arith.addi %seq_mask_329, %seq_mask_328 : tensor<128x1xi32> loc(#loc332)
      %seq_mask_341 = arith.constant 1 : i32 loc(#loc333)
      %seq_mask_342 = arith.constant 1 : i32 loc(#loc333)
      %seq_mask_343 = arith.constant dense<1> : tensor<128x1xi32> loc(#loc333)
      %seq_mask_344 = arith.extsi %seq_mask_340 : tensor<128x1xi32> to tensor<128x1xi64> loc(#loc333)
      %seq_mask_345 = arith.extsi %seq_mask_343 : tensor<128x1xi32> to tensor<128x1xi64> loc(#loc333)
      %seq_mask_346 = arith.addi %seq_mask_344, %seq_mask_345 : tensor<128x1xi64> loc(#loc333)
      %seq_mask_347 = arith.constant 2147483647 : i64 loc(#loc333)
      %seq_mask_348 = arith.constant -2147483648 : i64 loc(#loc333)
      %seq_mask_349 = arith.constant dense<2147483647> : tensor<128x1xi64> loc(#loc333)
      %seq_mask_350 = arith.cmpi sle, %seq_mask_346, %seq_mask_349 : tensor<128x1xi64> loc(#loc333)
      %seq_mask_351 = arith.constant dense<-2147483648> : tensor<128x1xi64> loc(#loc333)
      %seq_mask_352 = arith.cmpi sge, %seq_mask_346, %seq_mask_351 : tensor<128x1xi64> loc(#loc333)
      %seq_mask_353 = arith.andi %seq_mask_350, %seq_mask_352 : tensor<128x1xi1> loc(#loc333)
      %seq_mask_354 = arith.addi %seq_mask_340, %seq_mask_343 : tensor<128x1xi32> loc(#loc333)
      %seq_mask_355 = tt.broadcast %seq_mask : tensor<1x64xi32> -> tensor<128x64xi32> loc(#loc334)
      %seq_mask_356 = tt.broadcast %seq_mask_354 : tensor<128x1xi32> -> tensor<128x64xi32> loc(#loc334)
      %seq_mask_357 = arith.cmpi slt, %seq_mask_355, %seq_mask_356 : tensor<128x64xi32> loc(#loc334)
      %S = tt.call @"triton.language.standard.zeros____(0, 0)cconstexpr_128__(0, 1)cconstexpr_64__(1,)cconstexpr_fp32_"() : () -> tensor<128x64xf32> loc(#loc335)
      %S_358 = arith.constant 0.000000e+00 : f32 loc(#loc336)
      %S_359 = arith.constant dense<0.000000e+00> : tensor<128x64xf32> loc(#loc336)
      %S_360 = tt.dot %Q_149, %K_load_298, %S_359 : tensor<128x64xbf16> * tensor<64x64xbf16> -> tensor<128x64xf32> loc(#loc336)
      %S_361 = tt.splat %scale : f32 -> tensor<128x64xf32> loc(#loc337)
      %S_362 = arith.mulf %S_361, %S_360 : tensor<128x64xf32> loc(#loc337)
      %S_363 = arith.addf %S, %S_362 : tensor<128x64xf32> loc(#loc338)
      %S_364 = tt.expand_dims %query_mask_1_136 {axis = 1 : i32} : tensor<128xi1> -> tensor<128x1xi1> loc(#loc339)
      %S_365 = tt.expand_dims %query_mask_0_134 {axis = 1 : i32} : tensor<128xi1> -> tensor<128x1xi1> loc(#loc340)
      %S_366 = arith.andi %S_364, %S_365 : tensor<128x1xi1> loc(#loc341)
      %S_367 = tt.broadcast %S_366 : tensor<128x1xi1> -> tensor<128x64xi1> loc(#loc342)
      %S_368 = arith.andi %S_367, %seq_mask_357 : tensor<128x64xi1> loc(#loc342)
      %S_369 = arith.constant 0xFF800000 : f32 loc(#loc343)
      %S_370 = arith.constant 0xFF800000 : f32 loc(#loc343)
      %S_371 = arith.constant dense<0xFF800000> : tensor<128x64xf32> loc(#loc343)
      %S_372 = arith.select %S_368, %S_363, %S_371 : tensor<128x64xi1>, tensor<128x64xf32> loc(#loc343)
      %m_j = tt.call @"triton.language.standard.max__fp32S128_64S__(1,)cconstexpr_1__(2,)cconstexpr_False__(3,)cconstexpr_True__(4,)cconstexpr_False_"(%S_372) : (tensor<128x64xf32>) -> tensor<128xf32> loc(#loc344)
      %m_j_373 = arith.maxnumf %M_229, %m_j : tensor<128xf32> loc(#loc345)
      %m_j_374 = arith.constant 0xFF800000 : f32 loc(#loc346)
      %m_j_375 = arith.constant dense<0xFF800000> : tensor<128xf32> loc(#loc346)
      %m_j_376 = arith.cmpf ogt, %m_j_373, %m_j_375 : tensor<128xf32> loc(#loc346)
      %m_j_377 = arith.constant 0.000000e+00 : f32 loc(#loc347)
      %m_j_378 = arith.constant 0.000000e+00 : f32 loc(#loc347)
      %m_j_379 = arith.constant dense<0.000000e+00> : tensor<128xf32> loc(#loc347)
      %m_j_380 = arith.select %m_j_376, %m_j_373, %m_j_379 : tensor<128xi1>, tensor<128xf32> loc(#loc347)
      %P = tt.expand_dims %m_j_380 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc348)
      %P_381 = tt.broadcast %P : tensor<128x1xf32> -> tensor<128x64xf32> loc(#loc349)
      %P_382 = arith.subf %S_372, %P_381 : tensor<128x64xf32> loc(#loc349)
      %P_383 = math.exp %P_382 : tensor<128x64xf32> loc(#loc350)
      %l_j = tt.call @"triton.language.standard.sum__fp32S128_64S__(1,)cconstexpr_1__(2,)cconstexpr_False__(3,)cNone"(%P_383) : (tensor<128x64xf32>) -> tensor<128xf32> loc(#loc351)
      %alpha = arith.subf %M_229, %m_j_380 : tensor<128xf32> loc(#loc352)
      %alpha_384 = math.exp %alpha : tensor<128xf32> loc(#loc353)
      %acc_385 = tt.expand_dims %alpha_384 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc354)
      %acc_386 = tt.broadcast %acc_385 : tensor<128x1xf32> -> tensor<128x64xf32> loc(#loc355)
      %acc_387 = arith.mulf %acc_231, %acc_386 : tensor<128x64xf32> loc(#loc355)
      %L_388 = arith.mulf %L_230, %alpha_384 : tensor<128xf32> loc(#loc356)
      %L_389 = arith.addf %L_388, %l_j : tensor<128xf32> loc(#loc357)
      %acc_390 = arith.truncf %P_383 : tensor<128x64xf32> to tensor<128x64xbf16> loc(#loc358)
      %acc_391 = arith.constant 0.000000e+00 : f32 loc(#loc359)
      %acc_392 = arith.constant dense<0.000000e+00> : tensor<128x64xf32> loc(#loc359)
      %acc_393 = tt.dot %acc_390, %V_load_305, %acc_392 : tensor<128x64xbf16> * tensor<64x64xbf16> -> tensor<128x64xf32> loc(#loc359)
      %acc_394 = arith.addf %acc_387, %acc_393 : tensor<128x64xf32> loc(#loc360)
      scf.yield %m_j_380, %L_389, %acc_394 : tensor<128xf32>, tensor<128xf32>, tensor<128x64xf32> loc(#loc151)
    } loc(#loc398)
    %one_over_L = tt.expand_dims %acc_209#1 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc361)
    %one_over_L_210 = arith.constant 1.000000e+00 : f32 loc(#loc362)
    %one_over_L_211 = arith.constant 1.000000e+00 : f32 loc(#loc362)
    %one_over_L_212 = arith.constant dense<1.000000e+00> : tensor<128x1xf32> loc(#loc362)
    %one_over_L_213 = arith.divf %one_over_L_212, %one_over_L : tensor<128x1xf32> loc(#loc362)
    %acc_214 = tt.broadcast %one_over_L_213 : tensor<128x1xf32> -> tensor<128x64xf32> loc(#loc363)
    %acc_215 = arith.mulf %acc_209#2, %acc_214 : tensor<128x64xf32> loc(#loc363)
    %output_offset = tt.expand_dims %query_offset_0_82 {axis = 1 : i32} : tensor<128xi32> -> tensor<128x1xi32> loc(#loc364)
    %output_offset_216 = arith.extsi %output_offset : tensor<128x1xi32> to tensor<128x1xi64> loc(#loc365)
    %output_offset_217 = tt.splat %output_stride_0 : i64 -> tensor<128x1xi64> loc(#loc365)
    %output_offset_218 = arith.muli %output_offset_216, %output_offset_217 : tensor<128x1xi64> loc(#loc365)
    %output_offset_219 = tt.expand_dims %query_offset_1_108 {axis = 1 : i32} : tensor<128xi32> -> tensor<128x1xi32> loc(#loc366)
    %output_offset_220 = arith.extsi %output_offset_219 : tensor<128x1xi32> to tensor<128x1xi64> loc(#loc367)
    %output_offset_221 = tt.splat %output_stride_1 : i64 -> tensor<128x1xi64> loc(#loc367)
    %output_offset_222 = arith.muli %output_offset_220, %output_offset_221 : tensor<128x1xi64> loc(#loc367)
    %output_offset_223 = arith.addi %output_offset_218, %output_offset_222 : tensor<128x1xi64> loc(#loc368)
    %output_offset_224 = tt.expand_dims %offs_d {axis = 0 : i32} : tensor<64xi32> -> tensor<1x64xi32> loc(#loc369)
    %output_offset_225 = arith.extsi %output_offset_224 : tensor<1x64xi32> to tensor<1x64xi64> loc(#loc370)
    %output_offset_226 = tt.broadcast %output_offset_223 : tensor<128x1xi64> -> tensor<128x64xi64> loc(#loc370)
    %output_offset_227 = tt.broadcast %output_offset_225 : tensor<1x64xi64> -> tensor<128x64xi64> loc(#loc370)
    %output_offset_228 = arith.addi %output_offset_226, %output_offset_227 : tensor<128x64xi64> loc(#loc370)
    %36 = tt.expand_dims %dim_mask_133 {axis = 0 : i32} : tensor<64xi1> -> tensor<1x64xi1> loc(#loc162)
    %37 = tt.expand_dims %query_mask_0_134 {axis = 1 : i32} : tensor<128xi1> -> tensor<128x1xi1> loc(#loc163)
    %38 = tt.broadcast %36 : tensor<1x64xi1> -> tensor<128x64xi1> loc(#loc164)
    %39 = tt.broadcast %37 : tensor<128x1xi1> -> tensor<128x64xi1> loc(#loc164)
    %40 = arith.andi %38, %39 : tensor<128x64xi1> loc(#loc164)
    %41 = tt.expand_dims %query_mask_1_136 {axis = 1 : i32} : tensor<128xi1> -> tensor<128x1xi1> loc(#loc165)
    %42 = tt.broadcast %41 : tensor<128x1xi1> -> tensor<128x64xi1> loc(#loc166)
    %43 = arith.andi %40, %42 : tensor<128x64xi1> loc(#loc166)
    %44 = tt.splat %output_ptr : !tt.ptr<bf16> -> tensor<128x64x!tt.ptr<bf16>> loc(#loc167)
    %45 = tt.addptr %44, %output_offset_228 : tensor<128x64x!tt.ptr<bf16>>, tensor<128x64xi64> loc(#loc167)
    %46 = arith.truncf %acc_215 : tensor<128x64xf32> to tensor<128x64xbf16> loc(#loc168)
    tt.store %45, %46, %43 : tensor<128x64x!tt.ptr<bf16>> loc(#loc168)
    tt.return loc(#loc169)
  } loc(#loc)
  tt.func private @"unified_attention_aiter.find_seq_idx__Pi32_i32_i32__(3,)cconstexpr_16__(4,)cconstexpr_True_"(%query_start_len_ptr: !tt.ptr<i32> loc("query_start_len_ptr"(#loc170)), %target_idx: i32 loc("target_idx"(#loc170)), %right: i32 loc("right"(#loc373))) -> i32 attributes {noinline = false} {
    %left = arith.constant 0 : i32 loc(#loc394)
    %right_0:2 = scf.while (%left_2 = %left, %right_3 = %right) : (i32, i32) -> (i32, i32) {
      %8 = arith.cmpi slt, %left_2, %right_3 : i32 loc(#loc173)
      scf.condition(%8) %left_2, %right_3 : i32, i32 loc(#loc173)
    } do {
    ^bb0(%left_2: i32 loc("left"(#loc174)), %right_3: i32 loc("right"(#loc175))):
      %mid = arith.extsi %left_2 : i32 to i64 loc(#loc378)
      %mid_4 = arith.extsi %right_3 : i32 to i64 loc(#loc378)
      %mid_5 = arith.addi %mid, %mid_4 : i64 loc(#loc378)
      %mid_6 = arith.constant 2147483647 : i64 loc(#loc378)
      %mid_7 = arith.constant -2147483648 : i64 loc(#loc378)
      %mid_8 = arith.cmpi sle, %mid_5, %mid_6 : i64 loc(#loc378)
      %mid_9 = arith.cmpi sge, %mid_5, %mid_7 : i64 loc(#loc378)
      %mid_10 = arith.andi %mid_8, %mid_9 : i1 loc(#loc378)
      %mid_11 = arith.addi %left_2, %right_3 : i32 loc(#loc378)
      %mid_12 = arith.constant 2 : i32 loc(#loc379)
      %mid_13 = arith.constant 2 : i32 loc(#loc379)
      %right_14 = arith.divsi %mid_11, %mid_13 : i32 loc(#loc396)
      %val = tt.addptr %query_start_len_ptr, %right_14 : !tt.ptr<i32>, i32 loc(#loc380)
      %val_15 = tt.load %val : !tt.ptr<i32> loc(#loc381)
      %mid_val = arith.constant 16 : i32 loc(#loc382)
      %mid_val_16 = arith.constant 16 : i32 loc(#loc382)
      %mid_val_17 = arith.divsi %val_15, %mid_val_16 : i32 loc(#loc382)
      %mid_val_18 = arith.extsi %mid_val_17 : i32 to i64 loc(#loc383)
      %mid_val_19 = arith.extsi %right_14 : i32 to i64 loc(#loc383)
      %mid_val_20 = arith.addi %mid_val_18, %mid_val_19 : i64 loc(#loc383)
      %mid_val_21 = arith.constant 2147483647 : i64 loc(#loc383)
      %mid_val_22 = arith.constant -2147483648 : i64 loc(#loc383)
      %mid_val_23 = arith.cmpi sle, %mid_val_20, %mid_val_21 : i64 loc(#loc383)
      %mid_val_24 = arith.cmpi sge, %mid_val_20, %mid_val_22 : i64 loc(#loc383)
      %mid_val_25 = arith.andi %mid_val_23, %mid_val_24 : i1 loc(#loc383)
      %mid_val_26 = arith.addi %mid_val_17, %right_14 : i32 loc(#loc383)
      %8 = arith.cmpi sle, %mid_val_26, %target_idx : i32 loc(#loc182)
      %9:2 = scf.if %8 -> (i32, i32) {
        %left_27 = arith.constant 1 : i32 loc(#loc384)
        %left_28 = arith.constant 1 : i32 loc(#loc384)
        %left_29 = arith.extsi %right_14 : i32 to i64 loc(#loc384)
        %left_30 = arith.extsi %left_28 : i32 to i64 loc(#loc384)
        %left_31 = arith.addi %left_29, %left_30 : i64 loc(#loc384)
        %left_32 = arith.constant 2147483647 : i64 loc(#loc384)
        %left_33 = arith.constant -2147483648 : i64 loc(#loc384)
        %left_34 = arith.cmpi sle, %left_31, %left_32 : i64 loc(#loc384)
        %left_35 = arith.cmpi sge, %left_31, %left_33 : i64 loc(#loc384)
        %left_36 = arith.andi %left_34, %left_35 : i1 loc(#loc384)
        %left_37 = arith.addi %right_14, %left_28 : i32 loc(#loc397)
        scf.yield %left_37, %right_3 : i32, i32 loc(#loc397)
      } else {
        scf.yield %left_2, %right_14 : i32, i32 loc(#loc44)
      } loc(#loc183)
      scf.yield %9#0, %9#1 : i32, i32 loc(#loc185)
    } loc(#loc395)
    %c1_i32 = arith.constant 1 : i32 loc(#loc186)
    %c1_i32_1 = arith.constant 1 : i32 loc(#loc186)
    %0 = arith.extsi %right_0#0 : i32 to i64 loc(#loc186)
    %1 = arith.extsi %c1_i32_1 : i32 to i64 loc(#loc186)
    %2 = arith.subi %0, %1 : i64 loc(#loc186)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc186)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc186)
    %3 = arith.cmpi sle, %2, %c2147483647_i64 : i64 loc(#loc186)
    %4 = arith.cmpi sge, %2, %c-2147483648_i64 : i64 loc(#loc186)
    %5 = arith.andi %3, %4 : i1 loc(#loc186)
    %6 = arith.subi %right_0#0, %c1_i32_1 : i32 loc(#loc186)
    tt.return %6 : i32 loc(#loc187)
  ^bb1:  // no predecessors
    %7 = ub.poison : i32 loc(#loc188)
    tt.return %7 : i32 loc(#loc188)
  } loc(#loc170)
  tt.func private @"triton.language.standard.zeros____(0, 0)cconstexpr_128__(0, 1)cconstexpr_64__(1,)cconstexpr_fp32_"() -> tensor<128x64xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc190)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<128x64xf32> loc(#loc190)
    tt.return %cst_0 : tensor<128x64xf32> loc(#loc191)
  ^bb1:  // no predecessors
    %0 = ub.poison : tensor<128x64xf32> loc(#loc192)
    tt.return %0 : tensor<128x64xf32> loc(#loc192)
  } loc(#loc189)
  tt.func private @"unified_attention_aiter.cdiv_fn__i32__(1,)cconstexpr_64_"(%x: i32 loc("x"(#loc193))) -> i32 attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc194)
    %c64_i32_0 = arith.constant 64 : i32 loc(#loc194)
    %0 = arith.extsi %x : i32 to i64 loc(#loc194)
    %1 = arith.extsi %c64_i32_0 : i32 to i64 loc(#loc194)
    %2 = arith.addi %0, %1 : i64 loc(#loc194)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc194)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc194)
    %3 = arith.cmpi sle, %2, %c2147483647_i64 : i64 loc(#loc194)
    %4 = arith.cmpi sge, %2, %c-2147483648_i64 : i64 loc(#loc194)
    %5 = arith.andi %3, %4 : i1 loc(#loc194)
    %6 = arith.addi %x, %c64_i32_0 : i32 loc(#loc194)
    %c1_i32 = arith.constant 1 : i32 loc(#loc195)
    %c1_i32_1 = arith.constant 1 : i32 loc(#loc195)
    %7 = arith.extsi %6 : i32 to i64 loc(#loc195)
    %8 = arith.extsi %c1_i32_1 : i32 to i64 loc(#loc195)
    %9 = arith.subi %7, %8 : i64 loc(#loc195)
    %c2147483647_i64_2 = arith.constant 2147483647 : i64 loc(#loc195)
    %c-2147483648_i64_3 = arith.constant -2147483648 : i64 loc(#loc195)
    %10 = arith.cmpi sle, %9, %c2147483647_i64_2 : i64 loc(#loc195)
    %11 = arith.cmpi sge, %9, %c-2147483648_i64_3 : i64 loc(#loc195)
    %12 = arith.andi %10, %11 : i1 loc(#loc195)
    %13 = arith.subi %6, %c1_i32_1 : i32 loc(#loc195)
    %c64_i32_4 = arith.constant 64 : i32 loc(#loc196)
    %c64_i32_5 = arith.constant 64 : i32 loc(#loc196)
    %14 = arith.divsi %13, %c64_i32_5 : i32 loc(#loc196)
    tt.return %14 : i32 loc(#loc197)
  ^bb1:  // no predecessors
    %15 = ub.poison : i32 loc(#loc198)
    tt.return %15 : i32 loc(#loc198)
  } loc(#loc193)
  tt.func private @"triton.language.standard.max__fp32S128_64S__(1,)cconstexpr_1__(2,)cconstexpr_False__(3,)cconstexpr_True__(4,)cconstexpr_False_"(%input: tensor<128x64xf32> loc("input"(#loc199))) -> tensor<128xf32> attributes {noinline = false} {
    %0 = "tt.reduce"(%input) <{axis = 1 : i32}> ({
    ^bb0(%arg1: f32 loc(unknown), %arg2: f32 loc(unknown)):
      %2 = tt.call @triton.language.standard._elementwise_max__fp32_fp32__(%arg1, %arg2) : (f32, f32) -> f32 loc(#loc200)
      tt.reduce.return %2 : f32 loc(#loc200)
    }) : (tensor<128x64xf32>) -> tensor<128xf32> loc(#loc200)
    tt.return %0 : tensor<128xf32> loc(#loc201)
  ^bb1:  // no predecessors
    %1 = ub.poison : tensor<128xf32> loc(#loc202)
    tt.return %1 : tensor<128xf32> loc(#loc202)
  } loc(#loc199)
  tt.func private @triton.language.standard._elementwise_max__fp32_fp32__(%a: f32 loc("a"(#loc203)), %b: f32 loc("b"(#loc203))) -> f32 attributes {noinline = false} {
    %0 = arith.maxnumf %a, %b : f32 loc(#loc204)
    tt.return %0 : f32 loc(#loc205)
  ^bb1:  // no predecessors
    %1 = ub.poison : f32 loc(#loc206)
    tt.return %1 : f32 loc(#loc206)
  } loc(#loc203)
  tt.func private @"triton.language.standard.sum__fp32S128_64S__(1,)cconstexpr_1__(2,)cconstexpr_False__(3,)cNone"(%input: tensor<128x64xf32> loc("input"(#loc207))) -> tensor<128xf32> attributes {noinline = false} {
    %0 = "tt.reduce"(%input) <{axis = 1 : i32}> ({
    ^bb0(%arg1: f32 loc(unknown), %arg2: f32 loc(unknown)):
      %2 = tt.call @triton.language.standard._sum_combine__fp32_fp32__(%arg1, %arg2) : (f32, f32) -> f32 loc(#loc208)
      tt.reduce.return %2 : f32 loc(#loc208)
    }) : (tensor<128x64xf32>) -> tensor<128xf32> loc(#loc208)
    tt.return %0 : tensor<128xf32> loc(#loc209)
  ^bb1:  // no predecessors
    %1 = ub.poison : tensor<128xf32> loc(#loc210)
    tt.return %1 : tensor<128xf32> loc(#loc210)
  } loc(#loc207)
  tt.func private @triton.language.standard._sum_combine__fp32_fp32__(%a: f32 loc("a"(#loc211)), %b: f32 loc("b"(#loc211))) -> f32 attributes {noinline = false} {
    %0 = arith.addf %a, %b : f32 loc(#loc212)
    tt.return %0 : f32 loc(#loc213)
  ^bb1:  // no predecessors
    %1 = ub.poison : f32 loc(#loc214)
    tt.return %1 : f32 loc(#loc214)
  } loc(#loc211)
} loc(#loc)
#loc1 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":98:32)
#loc2 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":99:39)
#loc3 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":101:29)
#loc4 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":101:14)
#loc5 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":102:36)
#loc6 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":102:14)
#loc7 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":103:35)
#loc8 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":103:14)
#loc9 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":104:31)
#loc10 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":104:14)
#loc11 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":105:31)
#loc12 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":105:14)
#loc13 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":106:32)
#loc14 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":106:14)
#loc15 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":107:32)
#loc16 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":107:14)
#loc17 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":108:33)
#loc18 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":108:14)
#loc19 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":109:33)
#loc20 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":109:14)
#loc21 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":110:33)
#loc22 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":110:14)
#loc23 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":111:33)
#loc24 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":111:14)
#loc25 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":112:33)
#loc26 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":112:14)
#loc27 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":113:33)
#loc28 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":113:14)
#loc29 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":116:68)
#loc30 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":119:54)
#loc31 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":119:32)
#loc32 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":119:66)
#loc33 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":119:76)
#loc34 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":121:45)
#loc35 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":123:65)
#loc36 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":123:43)
#loc37 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":124:64)
#loc38 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":124:74)
#loc39 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":124:42)
#loc40 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":126:56)
#loc41 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":128:27)
#loc42 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":128:38)
#loc43 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":129:8)
#loc45 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":131:26)
#loc46 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":132:26)
#loc47 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":133:36)
#loc48 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":133:56)
#loc49 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":133:46)
#loc50 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":135:52)
#loc51 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":136:35)
#loc52 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":136:65)
#loc53 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":136:56)
#loc54 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":138:23)
#loc55 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":138:34)
#loc56 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":139:25)
#loc57 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":139:36)
#loc58 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":139:10)
#loc59 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":140:17)
#loc60 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":140:10)
#loc61 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":143:33)
#loc62 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":143:47)
#loc63 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":143:53)
#loc64 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":144:31)
#loc65 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":145:36)
#loc66 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":155:22)
#loc67 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":155:46)
#loc68 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":155:33)
#loc69 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":155:70)
#loc70 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":155:57)
#loc71 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":154:20)
#loc72 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":154:8)
#loc73 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":160:35)
#loc74 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":166:23)
#loc75 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":166:12)
#loc76 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":169:13)
#loc77 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":171:27)
#loc78 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":172:19)
#loc79 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":175:37)
#loc80 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":175:22)
#loc81 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":178:28)
#loc82 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":196:30)
#loc83 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":196:10)
#loc84 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":197:10)
#loc85 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":198:10)
#loc86 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":203:56)
#loc87 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":208:45)
#loc88 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":215:27)
#loc89 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":218:37)
#loc90 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":220:56)
#loc91 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":220:77)
#loc92 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":220:37)
#loc93 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":222:30)
#loc94 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":225:33)
#loc95 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":226:28)
#loc96 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":226:14)
#loc97 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":227:21)
#loc98 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":227:32)
#loc99 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":227:14)
#loc100 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":228:21)
#loc101 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":228:32)
#loc102 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":228:14)
#loc103 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":232:33)
#loc104 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":233:28)
#loc105 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":233:14)
#loc106 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":234:21)
#loc107 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":234:32)
#loc108 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":234:14)
#loc109 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":235:21)
#loc110 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":235:32)
#loc111 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":235:14)
#loc112 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":241:26)
#loc113 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":240:28)
#loc114 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":240:12)
#loc115 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":257:26)
#loc116 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":256:30)
#loc117 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":256:12)
#loc118 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":270:25)
#loc119 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":270:38)
#loc120 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":272:30)
#loc121 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":272:65)
#loc122 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":272:55)
#loc123 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":272:76)
#loc124 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":272:41)
#loc125 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":275:50)
#loc126 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":277:31)
#loc127 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":277:21)
#loc128 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":277:13)
#loc129 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":283:25)
#loc130 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":283:49)
#loc131 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":283:36)
#loc132 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":283:60)
#loc133 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":283:73)
#loc134 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":310:35)
#loc135 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":310:28)
#loc136 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":313:29)
#loc137 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":313:49)
#loc138 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":316:27)
#loc139 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":316:23)
#loc140 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":316:19)
#loc141 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":319:21)
#loc142 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":322:27)
#loc143 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":322:23)
#loc144 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":325:26)
#loc145 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":325:20)
#loc146 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":328:16)
#loc147 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":328:24)
#loc148 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":332:27)
#loc149 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":332:37)
#loc150 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":332:15)
#loc151 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":332:8)
#loc152 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":335:25)
#loc153 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":335:23)
#loc154 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":336:16)
#loc155 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":342:23)
#loc156 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":342:34)
#loc157 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":343:25)
#loc158 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":343:36)
#loc159 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":343:10)
#loc160 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":344:17)
#loc161 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":344:10)
#loc162 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":350:22)
#loc163 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":350:46)
#loc164 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":350:33)
#loc165 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":350:70)
#loc166 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":350:57)
#loc167 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":348:21)
#loc168 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":349:8)
#loc169 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":347:4)
#loc171 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":34:21)
#loc172 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":36:4)
#loc173 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":36:17)
#loc176 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":37:22)
#loc177 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":37:32)
#loc178 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":38:44)
#loc179 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":38:22)
#loc180 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":39:25)
#loc181 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":39:35)
#loc182 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":41:22)
#loc183 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":41:11)
#loc184 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":42:25)
#loc185 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":41:8)
#loc186 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":46:18)
#loc187 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":46:11)
#loc188 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":46:4)
#loc189 = loc("/app/OAI-triton/python/triton/language/standard.py":118:0)
#loc190 = loc("/app/OAI-triton/python/triton/language/standard.py":127:31)
#loc191 = loc("/app/OAI-triton/python/triton/language/standard.py":127:11)
#loc192 = loc("/app/OAI-triton/python/triton/language/standard.py":127:4)
#loc194 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":15:16)
#loc195 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":15:20)
#loc196 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":15:26)
#loc197 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":15:11)
#loc198 = loc("/app/OAI-triton/unified_attn_ubench/unified_attention_aiter.py":15:4)
#loc200 = loc("/app/OAI-triton/python/triton/language/standard.py":189:40)
#loc201 = loc("/app/OAI-triton/python/triton/language/standard.py":189:15)
#loc202 = loc("/app/OAI-triton/python/triton/language/standard.py":177:4)
#loc204 = loc("/app/OAI-triton/python/triton/language/standard.py":168:27)
#loc205 = loc("/app/OAI-triton/python/triton/language/standard.py":168:11)
#loc206 = loc("/app/OAI-triton/python/triton/language/standard.py":168:4)
#loc208 = loc("/app/OAI-triton/python/triton/language/standard.py":291:36)
#loc209 = loc("/app/OAI-triton/python/triton/language/standard.py":291:11)
#loc210 = loc("/app/OAI-triton/python/triton/language/standard.py":291:4)
#loc212 = loc("/app/OAI-triton/python/triton/language/standard.py":261:15)
#loc213 = loc("/app/OAI-triton/python/triton/language/standard.py":261:11)
#loc214 = loc("/app/OAI-triton/python/triton/language/standard.py":261:4)
#loc241 = loc("kv_head_idx"(#loc1))
#loc242 = loc("q_block_global_idx"(#loc2))
#loc243 = loc("seq_idx"(#loc29))
#loc244 = loc("q_block_start_idx"(#loc30))
#loc245 = loc("q_block_start_idx"(#loc31))
#loc246 = loc("q_block_start_idx"(#loc32))
#loc247 = loc("q_block_start_idx"(#loc33))
#loc248 = loc("q_block_local_idx"(#loc34))
#loc249 = loc("cur_batch_in_all_start_index"(#loc35))
#loc250 = loc("cur_batch_in_all_start_index"(#loc36))
#loc251 = loc("cur_batch_in_all_stop_index"(#loc37))
#loc252 = loc("cur_batch_in_all_stop_index"(#loc38))
#loc253 = loc("cur_batch_in_all_stop_index"(#loc39))
#loc254 = loc("cur_batch_query_len"(#loc40))
#loc255 = loc("offs_m"(#loc45))
#loc256 = loc("offs_d"(#loc46))
#loc257 = loc("query_pos"(#loc47))
#loc258 = loc("query_pos"(#loc48))
#loc259 = loc("query_pos"(#loc49))
#loc260 = loc("query_offset_0"(#loc50))
#loc261 = loc("query_offset_1"(#loc51))
#loc262 = loc("query_offset_1"(#loc52))
#loc263 = loc("query_offset_1"(#loc53))
#loc264 = loc("query_offset"(#loc54))
#loc265 = loc("query_offset"(#loc55))
#loc266 = loc("query_offset"(#loc56))
#loc267 = loc("query_offset"(#loc57))
#loc268 = loc("query_offset"(#loc58))
#loc269 = loc("query_offset"(#loc59))
#loc270 = loc("query_offset"(#loc60))
#loc271 = loc("dim_mask"(#loc61))
#loc272 = loc("dim_mask"(#loc62))
#loc273 = loc("dim_mask"(#loc63))
#loc274 = loc("query_mask_0"(#loc64))
#loc275 = loc("query_mask_1"(#loc65))
#loc276 = loc("Q"(#loc66))
#loc277 = loc("Q"(#loc67))
#loc278 = loc("Q"(#loc68))
#loc279 = loc("Q"(#loc69))
#loc280 = loc("Q"(#loc70))
#loc281 = loc("Q"(#loc71))
#loc282 = loc("Q"(#loc72))
#loc283 = loc("block_table_offset"(#loc73))
#loc284 = loc("M"(#loc74))
#loc285 = loc("M"(#loc75))
#loc286 = loc("M"(#loc76))
#loc287 = loc("L"(#loc77))
#loc288 = loc("acc"(#loc78))
#loc289 = loc("seq_len"(#loc79))
#loc290 = loc("seq_len"(#loc80))
#loc291 = loc("context_len"(#loc81))
#loc292 = loc("max_seq_prefix_len"(#loc82))
#loc293 = loc("max_seq_prefix_len"(#loc83))
#loc294 = loc("max_seq_prefix_len"(#loc84))
#loc295 = loc("max_seq_prefix_len"(#loc85))
#loc296 = loc("max_seq_prefix_len"(#loc86))
#loc297 = loc("num_blocks"(#loc87))
#loc298 = loc("num_blocks_start"(#loc88))
#loc299 = loc("M"(#loc89))
#loc300 = loc("physical_block_idx"(#loc90))
#loc301 = loc("physical_block_idx"(#loc91))
#loc302 = loc("physical_block_idx"(#loc92))
#loc303 = loc("offs_n"(#loc93))
#loc304 = loc("v_offset"(#loc94))
#loc305 = loc("v_offset"(#loc95))
#loc306 = loc("v_offset"(#loc96))
#loc307 = loc("v_offset"(#loc97))
#loc308 = loc("v_offset"(#loc98))
#loc309 = loc("v_offset"(#loc99))
#loc310 = loc("v_offset"(#loc100))
#loc311 = loc("v_offset"(#loc101))
#loc312 = loc("v_offset"(#loc102))
#loc313 = loc("k_offset"(#loc103))
#loc314 = loc("k_offset"(#loc104))
#loc315 = loc("k_offset"(#loc105))
#loc316 = loc("k_offset"(#loc106))
#loc317 = loc("k_offset"(#loc107))
#loc318 = loc("k_offset"(#loc108))
#loc319 = loc("k_offset"(#loc109))
#loc320 = loc("k_offset"(#loc110))
#loc321 = loc("k_offset"(#loc111))
#loc322 = loc("K_load"(#loc112))
#loc323 = loc("K_load"(#loc113))
#loc324 = loc("K_load"(#loc114))
#loc325 = loc("V_load"(#loc115))
#loc326 = loc("V_load"(#loc116))
#loc327 = loc("V_load"(#loc117))
#loc328 = loc("seq_offset"(#loc118))
#loc329 = loc("seq_offset"(#loc119))
#loc330 = loc("seq_mask"(#loc120))
#loc331 = loc("seq_mask"(#loc121))
#loc332 = loc("seq_mask"(#loc122))
#loc333 = loc("seq_mask"(#loc123))
#loc334 = loc("seq_mask"(#loc124))
#loc335 = loc("S"(#loc125))
#loc336 = loc("S"(#loc126))
#loc337 = loc("S"(#loc127))
#loc338 = loc("S"(#loc128))
#loc339 = loc("S"(#loc129))
#loc340 = loc("S"(#loc130))
#loc341 = loc("S"(#loc131))
#loc342 = loc("S"(#loc132))
#loc343 = loc("S"(#loc133))
#loc344 = loc("m_j"(#loc134))
#loc345 = loc("m_j"(#loc135))
#loc346 = loc("m_j"(#loc136))
#loc347 = loc("m_j"(#loc137))
#loc348 = loc("P"(#loc138))
#loc349 = loc("P"(#loc139))
#loc350 = loc("P"(#loc140))
#loc351 = loc("l_j"(#loc141))
#loc352 = loc("alpha"(#loc142))
#loc353 = loc("alpha"(#loc143))
#loc354 = loc("acc"(#loc144))
#loc355 = loc("acc"(#loc145))
#loc356 = loc("L"(#loc146))
#loc357 = loc("L"(#loc147))
#loc358 = loc("acc"(#loc148))
#loc359 = loc("acc"(#loc149))
#loc360 = loc("acc"(#loc150))
#loc361 = loc("one_over_L"(#loc152))
#loc362 = loc("one_over_L"(#loc153))
#loc363 = loc("acc"(#loc154))
#loc364 = loc("output_offset"(#loc155))
#loc365 = loc("output_offset"(#loc156))
#loc366 = loc("output_offset"(#loc157))
#loc367 = loc("output_offset"(#loc158))
#loc368 = loc("output_offset"(#loc159))
#loc369 = loc("output_offset"(#loc160))
#loc370 = loc("output_offset"(#loc161))
#loc374 = loc("left"(#loc171))
#loc375 = loc("left"(#loc172))
#loc378 = loc("mid"(#loc176))
#loc379 = loc("mid"(#loc177))
#loc380 = loc("val"(#loc178))
#loc381 = loc("val"(#loc179))
#loc382 = loc("mid_val"(#loc180))
#loc383 = loc("mid_val"(#loc181))
#loc384 = loc("left"(#loc184))
#loc392 = loc("L"(#loc299))
#loc394 = loc("left"(#loc374))
#loc395 = loc("right"(#loc375))
#loc396 = loc("right"(#loc379))
#loc397 = loc("left"(#loc384))
#loc398 = loc("acc"(#loc392))
